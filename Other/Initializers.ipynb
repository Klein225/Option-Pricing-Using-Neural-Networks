{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11910,
     "status": "ok",
     "timestamp": 1593680343580,
     "user": {
      "displayName": "Marc Klein",
      "photoUrl": "",
      "userId": "14297881284147348184"
     },
     "user_tz": -120
    },
    "id": "HhIih922RV9Q",
    "outputId": "ffcdf106-07a4-4271-8877-03f2db398536"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime, os\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from pylab import plt, mpl\n",
    "import time\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import optimize\n",
    "import scipy.integrate as integrate\n",
    "import scipy.special as special \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras import backend as BK\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmi8tz8lRV95"
   },
   "source": [
    "Lets read the CSV so we dont need to run it again, but can just load it when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "oUV-M-yvRV97",
    "outputId": "29b2c37b-c99a-4bc2-84b1-112aabc043b4"
   },
   "outputs": [],
   "source": [
    "#To read the import the csv-file, use:\n",
    "raw_Options_input = pd.read_csv (r\"/Users/Marcklein/Desktop/Master Thesis/Option pricing using Neural Networks/Python/Heston/Options_input.csv\")\n",
    "raw_Options_output = pd.read_csv (r\"/Users/Marcklein/Desktop/Master Thesis/Option pricing using Neural Networks/Python/Heston/Options_output.csv\")\n",
    "\n",
    "#Creates some unnamed column in the beginning, delete it:\n",
    "del raw_Options_input['Unnamed: 0']\n",
    "del raw_Options_output['Unnamed: 0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1593506558585,
     "user": {
      "displayName": "Marc Klein",
      "photoUrl": "",
      "userId": "14297881284147348184"
     },
     "user_tz": -120
    },
    "id": "UnMezLAORV9-",
    "outputId": "d2a7f1f7-b0b6-469b-dd9a-03da51121fb0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Options_input = raw_Options_input.copy()\n",
    "Options_output = raw_Options_output.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "altEsq-uRV-L"
   },
   "source": [
    "Since the standard deviation is calculated by taking the sum of the squared deviations from the mean, a zero standard deviation can only be possible when all the values of a variable are the same (all equal to the mean). In this case, those variables have no discriminative power so they can be removed from the analysis. They cannot improve any classification, clustering or regression task. Many implementations will do it for you or throw an error about a matrix calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zY0694xARV-O"
   },
   "source": [
    "### **Data preparation**\n",
    "\n",
    "We split our dataset into a training set and a test set (validation set is taken from the training set during model.fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-omBJ0xRV-O"
   },
   "outputs": [],
   "source": [
    "# 90% for training and validating\n",
    "train_dataset = Options_input.sample(frac=0.9, random_state=42)\n",
    "test_dataset = Options_input.drop(train_dataset.index)\n",
    "\n",
    "train_labels = Options_output.sample(frac=0.9, random_state=42)\n",
    "test_labels = Options_output.drop(train_labels.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yM9Vg1djRV-T"
   },
   "source": [
    "Check the overall statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1593506648378,
     "user": {
      "displayName": "Marc Klein",
      "photoUrl": "",
      "userId": "14297881284147348184"
     },
     "user_tz": -120
    },
    "id": "jcXaC5KDRV-U",
    "outputId": "38711e81-fb06-4cee-8b2d-f44b7713de02"
   },
   "outputs": [],
   "source": [
    "train_stats = train_dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1281,
     "status": "ok",
     "timestamp": 1593506654740,
     "user": {
      "displayName": "Marc Klein",
      "photoUrl": "",
      "userId": "14297881284147348184"
     },
     "user_tz": -120
    },
    "id": "7lk7tQZVRV-a",
    "outputId": "8a4b17d1-c7f7-4ce5-8deb-88422ff889c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input train data: (90000, 7)  Output train data: (90000, 10)\n",
      "Input test data: (10000, 7)  Output test data: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#normalize the data\n",
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset).values\n",
    "normed_test_data = norm(test_dataset).values\n",
    "\n",
    "#make the labels into numpy array just like the normed training data\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "\n",
    "#check the shapes\n",
    "print(\"Input train data:\", normed_train_data.shape, \" Output train data:\", train_labels.shape)\n",
    "print(\"Input test data:\", normed_test_data.shape, \" Output test data:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initializers**\n",
    "\n",
    "As mentioned earlier, we need to find a way to alleviate the unstable gradients problem. This is done by getting the signal to flow properly in both directions: in the forward direction when making predictions, and in the opposite direction when backpropagating gradients. We don't want the signals to explode and saturate, nor do we want them to die out. For the signal to flow properly, the authors  Xavier Glorot and Yoshua Bengio argued that we need the variance of the outputs of each layer to be equal to the variance of its inputs, and the gradients to have equal variance before and after flowing through a layer in the reverse direction.\n",
    "_____________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "352/352 - 3s - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 2/50\n",
      "352/352 - 4s - loss: 1.0985e-04 - mean_squared_error: 1.0985e-04\n",
      "Epoch 3/50\n",
      "352/352 - 3s - loss: 6.6655e-05 - mean_squared_error: 6.6655e-05\n",
      "Epoch 4/50\n",
      "352/352 - 3s - loss: 4.5681e-05 - mean_squared_error: 4.5681e-05\n",
      "Epoch 5/50\n",
      "352/352 - 4s - loss: 3.4819e-05 - mean_squared_error: 3.4819e-05\n",
      "Epoch 6/50\n",
      "352/352 - 3s - loss: 2.7275e-05 - mean_squared_error: 2.7275e-05\n",
      "Epoch 7/50\n",
      "352/352 - 4s - loss: 2.2240e-05 - mean_squared_error: 2.2240e-05\n",
      "Epoch 8/50\n",
      "352/352 - 3s - loss: 1.9184e-05 - mean_squared_error: 1.9184e-05\n",
      "Epoch 9/50\n",
      "352/352 - 3s - loss: 1.9034e-05 - mean_squared_error: 1.9034e-05\n",
      "Epoch 10/50\n",
      "352/352 - 4s - loss: 1.8866e-05 - mean_squared_error: 1.8866e-05\n",
      "Epoch 11/50\n",
      "352/352 - 3s - loss: 1.9018e-05 - mean_squared_error: 1.9018e-05\n",
      "Epoch 12/50\n",
      "352/352 - 2s - loss: 1.7764e-05 - mean_squared_error: 1.7764e-05\n",
      "Epoch 13/50\n",
      "352/352 - 2s - loss: 1.6610e-05 - mean_squared_error: 1.6610e-05\n",
      "Epoch 14/50\n",
      "352/352 - 2s - loss: 1.3650e-05 - mean_squared_error: 1.3650e-05\n",
      "Epoch 15/50\n",
      "352/352 - 2s - loss: 1.3670e-05 - mean_squared_error: 1.3670e-05\n",
      "Epoch 16/50\n",
      "352/352 - 2s - loss: 1.1482e-05 - mean_squared_error: 1.1482e-05\n",
      "Epoch 17/50\n",
      "352/352 - 2s - loss: 9.7531e-06 - mean_squared_error: 9.7531e-06\n",
      "Epoch 18/50\n",
      "352/352 - 2s - loss: 9.9985e-06 - mean_squared_error: 9.9985e-06\n",
      "Epoch 19/50\n",
      "352/352 - 2s - loss: 1.0816e-05 - mean_squared_error: 1.0816e-05\n",
      "Epoch 20/50\n",
      "352/352 - 2s - loss: 7.4515e-06 - mean_squared_error: 7.4515e-06\n",
      "Epoch 21/50\n",
      "352/352 - 3s - loss: 7.8545e-06 - mean_squared_error: 7.8545e-06\n",
      "Epoch 22/50\n",
      "352/352 - 2s - loss: 8.1511e-06 - mean_squared_error: 8.1511e-06\n",
      "Epoch 23/50\n",
      "352/352 - 2s - loss: 6.4688e-06 - mean_squared_error: 6.4688e-06\n",
      "Epoch 24/50\n",
      "352/352 - 2s - loss: 6.0682e-06 - mean_squared_error: 6.0682e-06\n",
      "Epoch 25/50\n",
      "352/352 - 2s - loss: 5.6478e-06 - mean_squared_error: 5.6478e-06\n",
      "Epoch 26/50\n",
      "352/352 - 2s - loss: 5.6664e-06 - mean_squared_error: 5.6664e-06\n",
      "Epoch 27/50\n",
      "352/352 - 2s - loss: 6.2201e-06 - mean_squared_error: 6.2201e-06\n",
      "Epoch 28/50\n",
      "352/352 - 2s - loss: 5.7808e-06 - mean_squared_error: 5.7808e-06\n",
      "Epoch 29/50\n",
      "352/352 - 2s - loss: 5.0347e-06 - mean_squared_error: 5.0347e-06\n",
      "Epoch 30/50\n",
      "352/352 - 2s - loss: 3.6235e-06 - mean_squared_error: 3.6235e-06\n",
      "Epoch 31/50\n",
      "352/352 - 3s - loss: 4.7463e-06 - mean_squared_error: 4.7463e-06\n",
      "Epoch 32/50\n",
      "352/352 - 4s - loss: 4.0703e-06 - mean_squared_error: 4.0703e-06\n",
      "Epoch 33/50\n",
      "352/352 - 3s - loss: 4.5901e-06 - mean_squared_error: 4.5901e-06\n",
      "Epoch 34/50\n",
      "352/352 - 4s - loss: 5.1960e-06 - mean_squared_error: 5.1960e-06\n",
      "Epoch 35/50\n",
      "352/352 - 4s - loss: 3.1158e-06 - mean_squared_error: 3.1158e-06\n",
      "Epoch 36/50\n",
      "352/352 - 3s - loss: 3.9798e-06 - mean_squared_error: 3.9798e-06\n",
      "Epoch 37/50\n",
      "352/352 - 3s - loss: 4.2148e-06 - mean_squared_error: 4.2148e-06\n",
      "Epoch 38/50\n",
      "352/352 - 3s - loss: 3.6701e-06 - mean_squared_error: 3.6701e-06\n",
      "Epoch 39/50\n",
      "352/352 - 3s - loss: 2.9526e-06 - mean_squared_error: 2.9526e-06\n",
      "Epoch 40/50\n",
      "352/352 - 3s - loss: 3.6269e-06 - mean_squared_error: 3.6269e-06\n",
      "Epoch 41/50\n",
      "352/352 - 3s - loss: 2.4026e-06 - mean_squared_error: 2.4026e-06\n",
      "Epoch 42/50\n",
      "352/352 - 3s - loss: 4.3976e-06 - mean_squared_error: 4.3976e-06\n",
      "Epoch 43/50\n",
      "352/352 - 3s - loss: 2.1495e-06 - mean_squared_error: 2.1495e-06\n",
      "Epoch 44/50\n",
      "352/352 - 3s - loss: 3.3933e-06 - mean_squared_error: 3.3933e-06\n",
      "Epoch 45/50\n",
      "352/352 - 3s - loss: 3.1881e-06 - mean_squared_error: 3.1881e-06\n",
      "Epoch 46/50\n",
      "352/352 - 3s - loss: 3.0550e-06 - mean_squared_error: 3.0550e-06\n",
      "Epoch 47/50\n",
      "352/352 - 3s - loss: 3.0907e-06 - mean_squared_error: 3.0907e-06\n",
      "Epoch 48/50\n",
      "352/352 - 3s - loss: 2.5338e-06 - mean_squared_error: 2.5338e-06\n",
      "Epoch 49/50\n",
      "352/352 - 3s - loss: 3.0299e-06 - mean_squared_error: 3.0299e-06\n",
      "Epoch 50/50\n",
      "352/352 - 3s - loss: 2.3906e-06 - mean_squared_error: 2.3906e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdaf155de90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(train_dataset.keys())\n",
    "output_size = 10\n",
    "hidden_layer_size = 100\n",
    "n_epochs = 50\n",
    "\n",
    "# Glorot he initializer\n",
    "weights_initializer_GH = keras.initializers.GlorotUniform()\n",
    "#Random Normal initializer\n",
    "weights_initializer_RN = tf.random_normal_initializer(mean=0.0, stddev=0.05, seed=None)\n",
    "\n",
    "#A function that trains and validates the model and returns the MSE \n",
    "def train_val_model(hparams):\n",
    "    model = keras.models.Sequential([\n",
    "            #Layer to be used as an entry point into a Network\n",
    "            keras.layers.InputLayer(input_shape=[len(train_dataset.keys())]),\n",
    "            #Dense layer 1\n",
    "            keras.layers.Dense(hidden_layer_size, activation='relu',\n",
    "                               kernel_initializer = hparams['initializer'],\n",
    "                               name='Layer_1'),\n",
    "        \n",
    "            #Batch Layer\n",
    "            #keras.layers.BatchNormalization(),\n",
    "        \n",
    "            #Dense layer 2\n",
    "            keras.layers.Dense(hidden_layer_size, activation='relu', \n",
    "                               kernel_initializer = hparams['initializer'],\n",
    "                               name='Layer_2'),\n",
    "        \n",
    "            #Batch Layer\n",
    "            #keras.layers.BatchNormalization(),\n",
    "        \n",
    "            #activation function is linear since we are doing regression\n",
    "            keras.layers.Dense(output_size, activation='linear', name='Output_layer')\n",
    "                                ])\n",
    "    \n",
    "    #use the adam optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-10, amsgrad=False, name='Adam')\n",
    "    \n",
    "    #Compiling the model\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='mean_squared_error', #Computes the mean of squares of errors between labels and predictions\n",
    "                  metrics=['mean_squared_error']) #Computes the mean squared error between y_true and y_pred\n",
    "    \n",
    "    # initialize TimeStopping callback \n",
    "    time_stopping_callback = tfa.callbacks.TimeStopping(seconds=5*60, verbose=1)\n",
    "    \n",
    "    #log our training in order to display it to tensorboard (provides great visual effects)\n",
    "    NAME = \"Heston_Tensorboard-{}\".format(int(time.time()))\n",
    "    tensorboard_callback = TensorBoard(log_dir=\"logs/fit/{}\".format(NAME),  \n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        write_images=False,\n",
    "        update_freq=\"epoch\",\n",
    "        profile_batch=2,\n",
    "        embeddings_freq=0,\n",
    "        embeddings_metadata=None)\n",
    "    \n",
    "    \n",
    "    #Training the network\n",
    "    history = model.fit(normed_train_data, train_labels, \n",
    "         epochs=n_epochs,\n",
    "         batch_size=len(normed_train_data), \n",
    "         verbose=2,\n",
    "         #validation_split=0.2,\n",
    "         callbacks=[tensorboard_callback, time_stopping_callback])\n",
    "    \n",
    "    return history\n",
    "\n",
    "train_val_model({'initializer': weights_initializer_GH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6010 (pid 34409), started 0:03:37 ago. (Use '!kill 34409' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ec4d01ecb35bd4cc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ec4d01ecb35bd4cc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6010;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "The Heston Model-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
