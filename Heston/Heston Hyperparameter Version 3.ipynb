{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Heston hyper-parameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11910,
     "status": "ok",
     "timestamp": 1593680343580,
     "user": {
      "displayName": "Marc Klein",
      "photoUrl": "",
      "userId": "14297881284147348184"
     },
     "user_tz": -120
    },
    "id": "HhIih922RV9Q",
    "outputId": "ffcdf106-07a4-4271-8877-03f2db398536"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime, os\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from pylab import plt, mpl\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import optimize\n",
    "import scipy.integrate as integrate\n",
    "import scipy.special as special \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmi8tz8lRV95"
   },
   "source": [
    "Load the Heston data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "oUV-M-yvRV97",
    "outputId": "29b2c37b-c99a-4bc2-84b1-112aabc043b4"
   },
   "outputs": [],
   "source": [
    "#To read the import the csv-file, use:\n",
    "raw_Options_input = pd.read_csv (r\"/Users/Marcklein/Desktop/Master Thesis/Option pricing using Neural Networks/Python/Heston/Heston_data_input.csv\")\n",
    "raw_Options_output = pd.read_csv (r\"/Users/Marcklein/Desktop/Master Thesis/Option pricing using Neural Networks/Python/Heston/Heston_data_output.csv\")\n",
    "\n",
    "#Creates some unnamed column in the beginning, delete it:\n",
    "del raw_Options_input['Unnamed: 0']\n",
    "del raw_Options_output['Unnamed: 0']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy it so we dont mess anything up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1593506558585,
     "user": {
      "displayName": "Marc Klein",
      "photoUrl": "",
      "userId": "14297881284147348184"
     },
     "user_tz": -120
    },
    "id": "UnMezLAORV9-",
    "outputId": "d2a7f1f7-b0b6-469b-dd9a-03da51121fb0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Options_input = raw_Options_input.copy()\n",
    "Options_output = raw_Options_output.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "altEsq-uRV-L"
   },
   "source": [
    "Since the standard deviation is calculated by taking the sum of the squared deviations from the mean, a zero standard deviation can only be possible when all the values of a variable are the same (all equal to the mean). In this case, those variables have no discriminative power so they can be removed from the analysis. They cannot improve any classification, clustering or regression task. Many implementations will do it for you or throw an error about a matrix calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zY0694xARV-O"
   },
   "source": [
    "### **Data preparation**\n",
    "\n",
    "We split our dataset into a training set and a test set (validation set is taken from the training set during model.fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-omBJ0xRV-O"
   },
   "outputs": [],
   "source": [
    "# 90% for training and validating\n",
    "train_dataset = Options_input.sample(frac=0.96666666666667, random_state=42)\n",
    "test_dataset = Options_input.drop(train_dataset.index)\n",
    "\n",
    "train_labels = Options_output.sample(frac=0.96666666666667, random_state=42)\n",
    "test_labels = Options_output.drop(train_labels.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yM9Vg1djRV-T"
   },
   "source": [
    "Check the overall statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1593506648378,
     "user": {
      "displayName": "Marc Klein",
      "photoUrl": "",
      "userId": "14297881284147348184"
     },
     "user_tz": -120
    },
    "id": "jcXaC5KDRV-U",
    "outputId": "38711e81-fb06-4cee-8b2d-f44b7713de02"
   },
   "outputs": [],
   "source": [
    "train_stats = train_dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1281,
     "status": "ok",
     "timestamp": 1593506654740,
     "user": {
      "displayName": "Marc Klein",
      "photoUrl": "",
      "userId": "14297881284147348184"
     },
     "user_tz": -120
    },
    "id": "7lk7tQZVRV-a",
    "outputId": "8a4b17d1-c7f7-4ce5-8deb-88422ff889c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input train data: (290000, 7)  Output train data: (290000, 10)\n",
      "Input test data: (10000, 7)  Output test data: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#normalize the data\n",
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset).values\n",
    "normed_test_data = norm(test_dataset).values\n",
    "\n",
    "#make the labels into numpy array just like the normed training data\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "\n",
    "#check the shapes\n",
    "print(\"Input train data:\", normed_train_data.shape, \" Output train data:\", train_labels.shape)\n",
    "print(\"Input test data:\", normed_test_data.shape, \" Output test data:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8O9gU8FqRV-c"
   },
   "source": [
    "### **The hyperparameter testing-model**\n",
    "\n",
    "We start by initializing all the hyperparameters that we want to asses. We then set the metrics of the model to \"mean squared error\". Since Tensorboard works with log files that are created during the training process we create logs for the training process that records the losses, metrics and other measures during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The hyperparameters & their values to be tested are stored in a special type called HParam\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([500, 750, 1000]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(.0001,.001))\n",
    "HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['relu', 'tanh', 'sigmoid']))\n",
    "HP_BATCHSIZE = hp.HParam('batch_size', hp.Discrete([32, 256, 1000]))\n",
    "\n",
    "#Setting the Metric to MSE (Mean Squared Error)\n",
    "METRIC_MSE = 'mean_squared_error'\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "\n",
    "#Creating & configuring log files\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_OPTIMIZER, HP_LEARNING_RATE, HP_ACTIVATION, HP_BATCHSIZE],\n",
    "        metrics=[hp.Metric(METRIC_MSE, display_name='mean_squared_error')],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function to train and validate the model which will take the hyperparameters as arguments. Each combination of hyperparameters will run for # epochs and the hyperparameters are provided in an hparams dictionary and used throughout the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight and bias initializers\n",
    "weights_initializer = keras.initializers.GlorotUniform(seed=42)\n",
    "bias_initializer = keras.initializers.Zeros()\n",
    "\n",
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "\n",
    "#A function that trains and validates the model on a variety of hyper-parameters and returns the MSE\n",
    "def train_val_model(hparams):\n",
    "    #Keras sequential model with Hyperparameters passed from the argument\n",
    "    model = keras.models.Sequential([\n",
    "            #Layer to be used as an entry point into a Network\n",
    "            keras.layers.InputLayer(input_shape=[len(train_dataset.keys())]),\n",
    "        \n",
    "            #Dense layer\n",
    "            keras.layers.Dense(hparams[HP_NUM_UNITS], kernel_initializer = weights_initializer,\n",
    "                               activation = hparams[HP_ACTIVATION], bias_initializer = bias_initializer,\n",
    "                              name='Layer_1'),\n",
    "        \n",
    "            #activation function is linear since we are doing regression\n",
    "            keras.layers.Dense(10, activation='linear', name='Output_layer')])\n",
    "    \n",
    "    if hparams[HP_OPTIMIZER] == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING_RATE], beta_1=0.9, beta_2=0.999,\n",
    "                             epsilon=1e-07, amsgrad=False, name='Adam')\n",
    "    elif hparams[HP_OPTIMIZER] == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=hparams[HP_LEARNING_RATE], nesterov=False, name='SGD')\n",
    "    elif hparams[HP_OPTIMIZER] == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=hparams[HP_LEARNING_RATE], rho=0.9, momentum=0.0, epsilon=1e-07, centered=False, name='RMSprop')\n",
    "    else:\n",
    "        raise ValueError(\"unexpected optimizer name: %r\" % (hparams[HP_OPTIMIZER],))\n",
    "    \n",
    "    \n",
    "    #Compiling the model\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='mean_squared_error', #Computes the mean of squares of errors between labels and predictions\n",
    "                  metrics=['mean_squared_error']) #Computes the mean squared error between y_true and y_pred\n",
    "    \n",
    "    #Training the network\n",
    "    model.fit(normed_train_data, train_labels, \n",
    "         batch_size=hparams[HP_BATCHSIZE], \n",
    "         epochs=50,\n",
    "         verbose=0,\n",
    "         validation_split=0.2,\n",
    "         callbacks=[PrintDot()])\n",
    "    \n",
    "    _, mse = model.evaluate(normed_test_data, test_labels)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will initiate the training process with the hyperparameters to be assessed and will create a summary based on the MSE value returned by the train_test_model function and writes the summary with the hyperparameters and final accuracy(MSE) in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        mse = train_val_model(hparams)\n",
    "        tf.summary.scalar(METRIC_MSE, mse, step=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the model for each combination of the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 6.0791e-07 - mean_squared_error: 6.0791e-07\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1202e-06 - mean_squared_error: 2.1202e-06\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 1.3074e-05 - mean_squared_error: 1.3074e-05\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4903e-04 - mean_squared_error: 1.4903e-04\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.2506e-05 - mean_squared_error: 1.2506e-05\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5801e-05 - mean_squared_error: 1.5801e-05\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.5212e-04 - mean_squared_error: 8.5212e-04\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5828e-06 - mean_squared_error: 1.5828e-06\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 7.1020e-06 - mean_squared_error: 7.1020e-06\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
      "--- Starting trial: run-12\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.3185e-04 - mean_squared_error: 1.3185e-04\n",
      "--- Starting trial: run-13\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 7.8440e-04 - mean_squared_error: 7.8440e-04\n",
      "--- Starting trial: run-14\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "--- Starting trial: run-15\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0741e-05 - mean_squared_error: 1.0741e-05\n",
      "--- Starting trial: run-16\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7851e-05 - mean_squared_error: 1.7851e-05\n",
      "--- Starting trial: run-17\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "--- Starting trial: run-18\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.8190e-05 - mean_squared_error: 1.8190e-05\n",
      "--- Starting trial: run-19\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7355e-05 - mean_squared_error: 1.7355e-05\n",
      "--- Starting trial: run-20\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0609 - mean_squared_error: 0.0609\n",
      "--- Starting trial: run-21\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 8.7026e-04 - mean_squared_error: 8.7026e-04\n",
      "--- Starting trial: run-22\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 9.3846e-04 - mean_squared_error: 9.3846e-04\n",
      "--- Starting trial: run-23\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0145 - mean_squared_error: 0.0145\n",
      "--- Starting trial: run-24\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.0635e-05 - mean_squared_error: 3.0635e-05\n",
      "--- Starting trial: run-25\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.5759e-05 - mean_squared_error: 4.5759e-05\n",
      "--- Starting trial: run-26\n",
      "{'num_units': 500, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0868 - mean_squared_error: 0.0868\n",
      "--- Starting trial: run-27\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.5383e-06 - mean_squared_error: 3.5383e-06\n",
      "--- Starting trial: run-28\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.2991e-06 - mean_squared_error: 8.2991e-06\n",
      "--- Starting trial: run-29\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.1327e-04 - mean_squared_error: 4.1327e-04\n",
      "--- Starting trial: run-30\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5176e-05 - mean_squared_error: 1.5176e-05\n",
      "--- Starting trial: run-31\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.1618e-06 - mean_squared_error: 8.1618e-06: 0s - loss: 8.0855e-06 - mean_squared_error: 8.\n",
      "--- Starting trial: run-32\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.6658e-04 - mean_squared_error: 8.6658e-04\n",
      "--- Starting trial: run-33\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.2806e-06 - mean_squared_error: 3.2806e-06\n",
      "--- Starting trial: run-34\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.8893e-05 - mean_squared_error: 1.8893e-05\n",
      "--- Starting trial: run-35\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.2483e-04 - mean_squared_error: 8.2483e-04\n",
      "--- Starting trial: run-36\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1182e-06 - mean_squared_error: 1.1182e-06\n",
      "--- Starting trial: run-37\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.1268e-05 - mean_squared_error: 2.1268e-05\n",
      "--- Starting trial: run-38\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "--- Starting trial: run-39\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 7.3075e-05 - mean_squared_error: 7.3075e-05\n",
      "--- Starting trial: run-40\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.8550e-04 - mean_squared_error: 4.8550e-04\n",
      "--- Starting trial: run-41\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "--- Starting trial: run-42\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4231e-05 - mean_squared_error: 1.4231e-05\n",
      "--- Starting trial: run-43\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.5158e-05 - mean_squared_error: 2.5158e-05\n",
      "--- Starting trial: run-44\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.6538e-04 - mean_squared_error: 8.6538e-04\n",
      "--- Starting trial: run-45\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.0578e-06 - mean_squared_error: 2.0578e-06\n",
      "--- Starting trial: run-46\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 5.1028e-05 - mean_squared_error: 5.1028e-05\n",
      "--- Starting trial: run-47\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "--- Starting trial: run-48\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 6.8700e-05 - mean_squared_error: 6.8700e-05\n",
      "--- Starting trial: run-49\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "--- Starting trial: run-50\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "--- Starting trial: run-51\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5423e-05 - mean_squared_error: 1.5423e-05\n",
      "--- Starting trial: run-52\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.5106e-05 - mean_squared_error: 4.5106e-05\n",
      "--- Starting trial: run-53\n",
      "{'num_units': 500, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.6347e-04 - mean_squared_error: 8.6347e-04\n",
      "--- Starting trial: run-54\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 6.1218e-07 - mean_squared_error: 6.1218e-07\n",
      "--- Starting trial: run-55\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.2901e-06 - mean_squared_error: 1.2901e-06\n",
      "--- Starting trial: run-56\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "--- Starting trial: run-57\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.2118e-05 - mean_squared_error: 1.2118e-05\n",
      "--- Starting trial: run-58\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.6124e-04 - mean_squared_error: 2.6124e-04\n",
      "--- Starting trial: run-59\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "--- Starting trial: run-60\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.3124e-05 - mean_squared_error: 1.3124e-05\n",
      "--- Starting trial: run-61\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4534e-05 - mean_squared_error: 1.4534e-05\n",
      "--- Starting trial: run-62\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 8.5477e-04 - mean_squared_error: 8.5477e-04\n",
      "--- Starting trial: run-63\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0174e-06 - mean_squared_error: 1.0174e-06\n",
      "--- Starting trial: run-64\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0595e-05 - mean_squared_error: 1.0595e-05\n",
      "--- Starting trial: run-65\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "--- Starting trial: run-66\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4545e-04 - mean_squared_error: 1.4545e-04\n",
      "--- Starting trial: run-67\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "--- Starting trial: run-68\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "--- Starting trial: run-69\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.3438e-05 - mean_squared_error: 1.3438e-05\n",
      "--- Starting trial: run-70\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 6.4191e-05 - mean_squared_error: 6.4191e-05\n",
      "--- Starting trial: run-71\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "--- Starting trial: run-72\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.3841e-05 - mean_squared_error: 1.3841e-05\n",
      "--- Starting trial: run-73\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.5281e-05 - mean_squared_error: 2.5281e-05\n",
      "--- Starting trial: run-74\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0709 - mean_squared_error: 0.0709\n",
      "--- Starting trial: run-75\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.6949e-04 - mean_squared_error: 8.6949e-04\n",
      "--- Starting trial: run-76\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "--- Starting trial: run-77\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "--- Starting trial: run-78\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.0156e-05 - mean_squared_error: 4.0156e-05\n",
      "--- Starting trial: run-79\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 7.3635e-05 - mean_squared_error: 7.3635e-05\n",
      "--- Starting trial: run-80\n",
      "{'num_units': 750, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0839 - mean_squared_error: 0.0839: 0s - loss: 0.0838 - mean_squared_error: \n",
      "--- Starting trial: run-81\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.9036e-06 - mean_squared_error: 2.9036e-06\n",
      "--- Starting trial: run-82\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.0219e-06 - mean_squared_error: 4.0219e-06\n",
      "--- Starting trial: run-83\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.9980e-04 - mean_squared_error: 2.9980e-04\n",
      "--- Starting trial: run-84\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1229e-05 - mean_squared_error: 1.1229e-05\n",
      "--- Starting trial: run-85\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 6.9156e-06 - mean_squared_error: 6.9156e-06\n",
      "--- Starting trial: run-86\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.6646e-04 - mean_squared_error: 8.6646e-04\n",
      "--- Starting trial: run-87\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 6.2909e-06 - mean_squared_error: 6.2909e-06\n",
      "--- Starting trial: run-88\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.4475e-05 - mean_squared_error: 2.4475e-05\n",
      "--- Starting trial: run-89\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.4267e-04 - mean_squared_error: 8.4267e-04\n",
      "--- Starting trial: run-90\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.9030e-07 - mean_squared_error: 8.9030e-07\n",
      "--- Starting trial: run-91\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3152e-05 - mean_squared_error: 1.3152e-05\n",
      "--- Starting trial: run-92\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "--- Starting trial: run-93\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.2785e-05 - mean_squared_error: 8.2785e-05\n",
      "--- Starting trial: run-94\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.1756e-04 - mean_squared_error: 4.1756e-04\n",
      "--- Starting trial: run-95\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "--- Starting trial: run-96\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.2850e-05 - mean_squared_error: 1.2850e-05\n",
      "--- Starting trial: run-97\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3713e-04 - mean_squared_error: 1.3713e-04\n",
      "--- Starting trial: run-98\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 8.5681e-04 - mean_squared_error: 8.5681e-04\n",
      "--- Starting trial: run-99\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6912e-06 - mean_squared_error: 1.6912e-06\n",
      "--- Starting trial: run-100\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 6.4506e-05 - mean_squared_error: 6.4506e-05\n",
      "--- Starting trial: run-101\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "--- Starting trial: run-102\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4408e-04 - mean_squared_error: 1.4408e-04\n",
      "--- Starting trial: run-103\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "--- Starting trial: run-104\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "--- Starting trial: run-105\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.6298e-05 - mean_squared_error: 1.6298e-05\n",
      "--- Starting trial: run-106\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.7949e-05 - mean_squared_error: 8.7949e-05\n",
      "--- Starting trial: run-107\n",
      "{'num_units': 750, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 8.6487e-04 - mean_squared_error: 8.6487e-04\n",
      "--- Starting trial: run-108\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.0501e-07 - mean_squared_error: 3.0501e-07: 0s - loss: 3.1149e-07 - mean_squared_error: 3.1149\n",
      "--- Starting trial: run-109\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7768e-06 - mean_squared_error: 1.7768e-06\n",
      "--- Starting trial: run-110\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "--- Starting trial: run-111\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5805e-05 - mean_squared_error: 1.5805e-05\n",
      "--- Starting trial: run-112\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.8282e-04 - mean_squared_error: 4.8282e-04\n",
      "--- Starting trial: run-113\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "--- Starting trial: run-114\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5764e-05 - mean_squared_error: 1.5764e-05\n",
      "--- Starting trial: run-115\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4518e-05 - mean_squared_error: 1.4518e-05\n",
      "--- Starting trial: run-116\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.5458e-04 - mean_squared_error: 8.5458e-04\n",
      "--- Starting trial: run-117\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 9.2106e-07 - mean_squared_error: 9.2106e-07\n",
      "--- Starting trial: run-118\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.6823e-06 - mean_squared_error: 8.6823e-06\n",
      "--- Starting trial: run-119\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "--- Starting trial: run-120\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.9623e-04 - mean_squared_error: 3.9623e-04\n",
      "--- Starting trial: run-121\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "--- Starting trial: run-122\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "--- Starting trial: run-123\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1304e-05 - mean_squared_error: 1.1304e-05\n",
      "--- Starting trial: run-124\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.8996e-05 - mean_squared_error: 3.8996e-05\n",
      "--- Starting trial: run-125\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "--- Starting trial: run-126\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0373e-05 - mean_squared_error: 1.0373e-05\n",
      "--- Starting trial: run-127\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.1681e-05 - mean_squared_error: 3.1681e-05\n",
      "--- Starting trial: run-128\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0612 - mean_squared_error: 0.0612\n",
      "--- Starting trial: run-129\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.7329e-04 - mean_squared_error: 8.7329e-04\n",
      "--- Starting trial: run-130\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "--- Starting trial: run-131\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "--- Starting trial: run-132\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 5.4050e-05 - mean_squared_error: 5.4050e-05\n",
      "--- Starting trial: run-133\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1513e-04 - mean_squared_error: 1.1513e-04\n",
      "--- Starting trial: run-134\n",
      "{'num_units': 1000, 'learning_rate': 0.0001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0798 - mean_squared_error: 0.0798\n",
      "--- Starting trial: run-135\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.6989e-06 - mean_squared_error: 2.6989e-06\n",
      "--- Starting trial: run-136\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.9945e-06 - mean_squared_error: 4.9945e-06\n",
      "--- Starting trial: run-137\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.5058e-04 - mean_squared_error: 2.5058e-04\n",
      "--- Starting trial: run-138\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4740e-05 - mean_squared_error: 1.4740e-05\n",
      "--- Starting trial: run-139\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.4833e-06 - mean_squared_error: 4.4833e-06\n",
      "--- Starting trial: run-140\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.6628e-04 - mean_squared_error: 8.6628e-04\n",
      "--- Starting trial: run-141\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 5.9431e-06 - mean_squared_error: 5.9431e-06\n",
      "--- Starting trial: run-142\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7935e-05 - mean_squared_error: 1.7935e-05\n",
      "--- Starting trial: run-143\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 32, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.4420e-04 - mean_squared_error: 8.4420e-04\n",
      "--- Starting trial: run-144\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.6044e-06 - mean_squared_error: 3.6044e-06\n",
      "--- Starting trial: run-145\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7095e-05 - mean_squared_error: 1.7095e-05\n",
      "--- Starting trial: run-146\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "--- Starting trial: run-147\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.2352e-04 - mean_squared_error: 2.2352e-04\n",
      "--- Starting trial: run-148\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 4.8043e-04 - mean_squared_error: 4.8043e-04\n",
      "--- Starting trial: run-149\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 9.6990e-04 - mean_squared_error: 9.6990e-04\n",
      "--- Starting trial: run-150\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1815e-05 - mean_squared_error: 1.1815e-05\n",
      "--- Starting trial: run-151\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.4679e-05 - mean_squared_error: 3.4679e-05\n",
      "--- Starting trial: run-152\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 264, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.5572e-04 - mean_squared_error: 8.5572e-04\n",
      "--- Starting trial: run-153\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1736e-05 - mean_squared_error: 1.1736e-05\n",
      "--- Starting trial: run-154\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 7.6494e-05 - mean_squared_error: 7.6494e-05\n",
      "--- Starting trial: run-155\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'relu', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "--- Starting trial: run-156\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.3565e-04 - mean_squared_error: 1.3565e-04\n",
      "--- Starting trial: run-157\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_squared_error: 0.0188\n",
      "--- Starting trial: run-158\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'sigmoid', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "--- Starting trial: run-159\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'adam'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7789e-05 - mean_squared_error: 1.7789e-05\n",
      "--- Starting trial: run-160\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'rmsprop'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 3.4396e-05 - mean_squared_error: 3.4396e-05\n",
      "--- Starting trial: run-161\n",
      "{'num_units': 1000, 'learning_rate': 0.001, 'batch_size': 1000, 'activation': 'tanh', 'optimizer': 'sgd'}\n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 8.5195e-04 - mean_squared_error: 8.5195e-04\n",
      "CPU times: user 13h 56min 51s, sys: 1h 43min 51s, total: 15h 40min 42s\n",
      "Wall time: 7h 58min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#A unique number for each training session\n",
    "session_num = 0\n",
    "\n",
    "#Nested for loop training with all possible  combinathon of hyperparameters\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for learning_rate in (HP_LEARNING_RATE.domain.min_value, HP_LEARNING_RATE.domain.max_value):\n",
    "        for batch_size in HP_BATCHSIZE.domain.values:\n",
    "            for activation in HP_ACTIVATION.domain.values:\n",
    "                for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                    hparams = {\n",
    "                        HP_NUM_UNITS: num_units,\n",
    "                        HP_LEARNING_RATE: learning_rate,\n",
    "                        HP_BATCHSIZE: batch_size,\n",
    "                        HP_ACTIVATION: activation,\n",
    "                        HP_OPTIMIZER: optimizer\n",
    "                        }\n",
    "                    run_name = \"run-%d\" % session_num\n",
    "                    print('--- Starting trial: %s' % run_name)\n",
    "                    print({h.name: hparams[h] for h in hparams})\n",
    "                    run('logs/hparam_tuning/' + run_name, hparams)\n",
    "                    session_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its time to launch TensorBoard. Use the following commands to launch tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 6114), started 9:09:24 ago. (Use '!kill 6114' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-79a9b9859c2d1479\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-79a9b9859c2d1479\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it is launched, you will see a beautiful dashboard. Click on the HPARAMS tab to see the hyperparameter logs.\n",
    "\n",
    "In \"Table View\" all the hyperparameter combinations and the respective accuracy will be displayed in a beautiful table as. The left side of the dashboard provides a number of filtering capabilities such as sorting based on the metric, filtering based on specific type or value of hyperparameter, filtering based on status etc.\n",
    "\n",
    "The Parallel Coordinates View shows each run as a line going through an axis for each hyperparameter and metric. The interactive plot allows us to mark a region which will highlight only the runs that pass through it. The units if each hyperparameter can also be changed between linear, logarithmic and quantile values. This is extremely useful in understanding the relationships between the hyperparameters. We can select the optimum hyperparameters just by selecting the least MSE (run your mouse over the line)\n",
    "\n",
    "The Scatter Plot View plots each of the hyperparameter and the given metric against the metric.This helps us understand how different values of each parameter correlates to the metric.\n",
    "\n",
    "LINKS:\n",
    "\n",
    "https://analyticsindiamag.com/parameter-tuning-tensorboard/\n",
    "\n",
    "https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams\n",
    "\n",
    "https://medium.com/ml-book/neural-networks-hyperparameter-tuning-in-tensorflow-2-0-a7b4e2b574a1\n",
    "\n",
    "https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/hparams/summary_v2.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEAS: \n",
    "\n",
    "- HP_LEARNING_RATE = hp.HParam(\"learning_rate\", hp.RealInterval(1e-5, 1e-1))\n",
    "\n",
    "- HP_L2 = hp.HParam('l2 regularizer', hp.RealInterval(.001,.01))\n",
    "\n",
    "- HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.3, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "The Heston Model-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
